{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46f3c65-b01f-444a-999c-6226b186585b",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4ec540-bad6-4748-91f2-7e6c0f5b63c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: ../../\n",
      "  Subdirectory: Week04\n",
      "  Subdirectory: Week03\n",
      "  Subdirectory: Week05\n",
      "  Subdirectory: Week01\n",
      "  Subdirectory: Week02\n",
      "Directory: ../../Week04\n",
      "  Subdirectory: Monday\n",
      "  Subdirectory: Friday\n",
      "  Subdirectory: Wednesday\n",
      "Directory: ../../Week04/Monday\n",
      "  File: In Class Assignment W04M.ipynb\n",
      "Directory: ../../Week04/Friday\n",
      "Directory: ../../Week04/Wednesday\n",
      "  File: DataContainers.ipynb\n",
      "Directory: ../../Week03\n",
      "  Subdirectory: Monday\n",
      "Directory: ../../Week03/Monday\n",
      "  File: umary.py\n",
      "Directory: ../../Week05\n",
      "  Subdirectory: Monday\n",
      "  Subdirectory: Friday\n",
      "Directory: ../../Week05/Monday\n",
      "  File: baseball.csv\n",
      "  File: data-sources.ipynb\n",
      "Directory: ../../Week05/Friday\n",
      "  Subdirectory: .ipynb_checkpoints\n",
      "  File: Untitled.ipynb\n",
      "  File: DataFrame.ipynb\n",
      "  File: homework-wo5f.py\n",
      "Directory: ../../Week05/Friday/.ipynb_checkpoints\n",
      "  File: Untitled-checkpoint.ipynb\n",
      "Directory: ../../Week01\n",
      "Directory: ../../Week02\n",
      "  Subdirectory: Monday\n",
      "Directory: ../../Week02/Monday\n",
      "  File: Quiz01.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"../../\"):\n",
    "    print(\"Directory: \" + root)\n",
    "\n",
    "    # Skip GIT files\n",
    "    if \".git\" in dirs:\n",
    "        dirs.remove(\".git\")\n",
    "\n",
    "    for dir_name in dirs:\n",
    "        print(\"  Subdirectory: \" + dir_name)\n",
    "    for file_name in files:\n",
    "        print(\"  File: \" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b331f-5e93-4dc8-8a77-e91294244b90",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac2e7f1-d912-4efa-86b0-be9be39f1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 Chevy Camaro With Boosted Vortec I6 Swap Cracks 1,000 HP to the Tire\n",
      "An American Tuner Built a 10-Second VB Subaru WRX—and It’s Not Done Yet\n",
      "Supercharged 1966 Dodge RV Is a Hot-Rod House on Wheels With 770 HP\n",
      "A Crown Vic Can Do 2,000-RPM Drifts If You Swap in a Twin-Turbo Tank Engine\n",
      "Man Worth $206B Asked West Coast Customs to Build His Wife a Porsche Minivan\n",
      "An Amphibious Ford Mustang Is the Best Way to Troll Yacht Clubs\n",
      "Hear This 13,000-RPM Mazda Miata With a Motorcycle Engine Rip \n",
      "Watch a 2,700-HP, Triple-Turbo Cummins Ram Detonate in Slow-Mo\n",
      "The Log Hopper Is the Hyper-Specialized Off-Trailer You Didn’t Know You Wanted\n",
      "1,370-HP Time Attack Audi R8 Is a Maxed Forza Build in Real Life\n",
      "Ford RS200-Engined Hill Climber Uses Helicopter Turbine Engine for a Turbo\n",
      "This BMW ‘858CSL’ Is the Coolest E31 8 Series Build We’ve Ever Seen\n",
      "There’s an Insane 1969 Plymouth Satellite Drift Car Stalking the East Coast\n",
      "Toyota V12-Swapped Lamborghini Countach Clone Is a DIY Supercar Done Right\n",
      "Buy This Twin-Engine Geo Metro If You Absolutely Must Die in a Fiery Crash\n",
      "These Retro Mercedes G-Wagen Builds Are for Bad Guys on Vacation\n",
      "This Ford V10 With DOHC Heads and F1-Style Exhaust Will Split the Earth in Two\n",
      "Retro 2024 Chevy Suburban Build Is the Vintage Trim GM Should Bring Back\n",
      "This RWD Ford Focus With a 725-HP V8 Is a Wild Alternate-Reality Focus RS—And It’s For Sale\n",
      "A $120 Turbo Cut This Slant-Six Dodge Truck’s 0-60 Time in Half\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(title)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#data[1].append(link)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m df\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/.anaconda3/envs/jupyter-env/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/.anaconda3/envs/jupyter-env/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/.anaconda3/envs/jupyter-env/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.anaconda3/envs/jupyter-env/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup as BSoup\n",
    "import pandas as pd\n",
    "\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "theDrive = \"https://www.thedrive.com/category/builds\"\n",
    "\n",
    "session = requests.Session()\n",
    "content = session.get(theDrive, verify=False).content\n",
    "soup = BSoup(content, \"html.parser\")\n",
    "\n",
    "data = {\"Title\": [],\n",
    "        \"Url\"  : []}\n",
    "\n",
    "list = []\n",
    "\n",
    "# Find all instances of the proper class which represents a headline.\n",
    "News = soup.find_all('a', class_=\"card-post-title-link\")\n",
    "for article in News:\n",
    "    # Parse out the data out of the html.\n",
    "    title = article.find('span', class_=\"desktop\").getText()\n",
    "\n",
    "    print(title)\n",
    "    #link = urljoin(theDrive, article['href'])\n",
    "    data[\"Title\"].append(title)\n",
    "    #data[1].append(link)\n",
    "\n",
    "df= pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87dfbcb-7736-4fca-ad21-978321268248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
