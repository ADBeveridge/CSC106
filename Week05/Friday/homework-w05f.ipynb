{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46f3c65-b01f-444a-999c-6226b186585b",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4ec540-bad6-4748-91f2-7e6c0f5b63c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: ../../\n",
      "  Subdirectory: Week04\n",
      "  Subdirectory: Week03\n",
      "  Subdirectory: Week05\n",
      "  Subdirectory: Week01\n",
      "  Subdirectory: Week02\n",
      "Directory: ../../Week04\n",
      "  Subdirectory: Monday\n",
      "  Subdirectory: Friday\n",
      "  Subdirectory: Wednesday\n",
      "Directory: ../../Week04/Monday\n",
      "  File: In Class Assignment W04M.ipynb\n",
      "Directory: ../../Week04/Friday\n",
      "Directory: ../../Week04/Wednesday\n",
      "  File: DataContainers.ipynb\n",
      "Directory: ../../Week03\n",
      "  Subdirectory: Monday\n",
      "Directory: ../../Week03/Monday\n",
      "  File: umary.py\n",
      "Directory: ../../Week05\n",
      "  Subdirectory: Monday\n",
      "  Subdirectory: Friday\n",
      "Directory: ../../Week05/Monday\n",
      "  File: baseball.csv\n",
      "  File: data-sources.ipynb\n",
      "Directory: ../../Week05/Friday\n",
      "  Subdirectory: .ipynb_checkpoints\n",
      "  File: Untitled.ipynb\n",
      "  File: DataFrame.ipynb\n",
      "  File: homework-wo5f.py\n",
      "Directory: ../../Week05/Friday/.ipynb_checkpoints\n",
      "  File: Untitled-checkpoint.ipynb\n",
      "Directory: ../../Week01\n",
      "Directory: ../../Week02\n",
      "  Subdirectory: Monday\n",
      "Directory: ../../Week02/Monday\n",
      "  File: Quiz01.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"../../\"):\n",
    "    print(\"Directory: \" + root)\n",
    "\n",
    "    # Skip GIT files\n",
    "    if \".git\" in dirs:\n",
    "        dirs.remove(\".git\")\n",
    "\n",
    "    for dir_name in dirs:\n",
    "        print(\"  Subdirectory: \" + dir_name)\n",
    "    for file_name in files:\n",
    "        print(\"  File: \" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b331f-5e93-4dc8-8a77-e91294244b90",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ac2e7f1-d912-4efa-86b0-be9be39f1ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title  \\\n",
      "0   2010 Chevy Camaro With Boosted Vortec I6 Swap ...   \n",
      "1   An American Tuner Built a 10-Second VB Subaru ...   \n",
      "2   Supercharged 1966 Dodge RV Is a Hot-Rod House ...   \n",
      "3   A Crown Vic Can Do 2,000-RPM Drifts If You Swa...   \n",
      "4   Man Worth $206B Asked West Coast Customs to Bu...   \n",
      "5   An Amphibious Ford Mustang Is the Best Way to ...   \n",
      "6   Hear This 13,000-RPM Mazda Miata With a Motorc...   \n",
      "7   Watch a 2,700-HP, Triple-Turbo Cummins Ram Det...   \n",
      "8   The Log Hopper Is the Hyper-Specialized Off-Tr...   \n",
      "9   1,370-HP Time Attack Audi R8 Is a Maxed Forza ...   \n",
      "10  Ford RS200-Engined Hill Climber Uses Helicopte...   \n",
      "11  This BMW ‘858CSL’ Is the Coolest E31 8 Series ...   \n",
      "12  There’s an Insane 1969 Plymouth Satellite Drif...   \n",
      "13  Toyota V12-Swapped Lamborghini Countach Clone ...   \n",
      "14  Buy This Twin-Engine Geo Metro If You Absolute...   \n",
      "15  These Retro Mercedes G-Wagen Builds Are for Ba...   \n",
      "16  This Ford V10 With DOHC Heads and F1-Style Exh...   \n",
      "17  Retro 2024 Chevy Suburban Build Is the Vintage...   \n",
      "18  This RWD Ford Focus With a 725-HP V8 Is a Wild...   \n",
      "19  A $120 Turbo Cut This Slant-Six Dodge Truck’s ...   \n",
      "\n",
      "                                                  Url  \n",
      "0   https://www.thedrive.com/news/2010-chevy-camar...  \n",
      "1   https://www.thedrive.com/news/an-american-tune...  \n",
      "2   https://www.thedrive.com/news/supercharged-196...  \n",
      "3   https://www.thedrive.com/news/a-crown-vic-can-...  \n",
      "4   https://www.thedrive.com/news/man-worth-206b-a...  \n",
      "5   https://www.thedrive.com/news/an-amphibious-fo...  \n",
      "6   https://www.thedrive.com/news/hear-this-13000-...  \n",
      "7   https://www.thedrive.com/news/watch-a-2700-hp-...  \n",
      "8   https://www.thedrive.com/news/the-log-hopper-i...  \n",
      "9   https://www.thedrive.com/news/1370-hp-time-att...  \n",
      "10  https://www.thedrive.com/news/ford-rs200-engin...  \n",
      "11  https://www.thedrive.com/news/this-bmw-858csl-...  \n",
      "12  https://www.thedrive.com/news/theres-an-insane...  \n",
      "13  https://www.thedrive.com/news/culture/toyota-v...  \n",
      "14  https://www.thedrive.com/news/this-12-cylinder...  \n",
      "15  https://www.thedrive.com/news/these-retro-merc...  \n",
      "16  https://www.thedrive.com/news/culture/ford-v10...  \n",
      "17  https://www.thedrive.com/news/retro-2024-chevy...  \n",
      "18  https://www.thedrive.com/news/culture/this-rwd...  \n",
      "19  https://www.thedrive.com/news/culture/a-120-tu...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup as BSoup\n",
    "import pandas as pd\n",
    "\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "theDrive = \"https://www.thedrive.com/category/builds\"\n",
    "\n",
    "session = requests.Session()\n",
    "content = session.get(theDrive, verify=False).content\n",
    "soup = BSoup(content, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "titles = []\n",
    "urls = []\n",
    "\n",
    "# Find all instances of the proper class which represents a headline.\n",
    "News = soup.find_all('a', class_=\"card-post-title-link\")\n",
    "for article in News:\n",
    "    # Parse out the data out of the html.\n",
    "    title = article.find('span', class_=\"desktop\").getText()\n",
    "    titles.append(title)\n",
    "\n",
    "    link = urljoin(theDrive, article['href'])\n",
    "    urls.append(link)\n",
    "\n",
    "data = {\"Title\": titles,\n",
    "        \"Url\"  : urls}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87dfbcb-7736-4fca-ad21-978321268248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
